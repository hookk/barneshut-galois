\subsection{Ray Tracer}
\label{sec:cases:ray}

\todonaps{THIS}
This was the most different and challenging test case to implement. The original source code, ``\textit{smallpt: Global Illumination in 99 lines of C++}'', is explained and available in \cite{99lines}.

The original implementation of \smallpt relied on OpenMP to distribute workload accross threads. The workload were pixels, meaning that each thread would be responsible for a subset of the total pixels of the image. For each pixel, the corresponding thread would launch a given number of rays (given as a parameter) using Monte Carlo to add some randomness to their direction. Each ray was then checked against the entire list of objects composing the scene, which was implemented as a naive vector of spheres \footnote{\smallpt was optimized for code size, not speed. All objects were simply spheres (even the walls), and no acceleration structure was provided, minimizing amount of code}.

After each collision, one or more subrays might be generated, depending on the properties of the object with which the ray collided. The ray might generate a reflected or refracted ray, or a combination of both. After the path of rays reaches a given depth (also given as a parameter), Russian Roulette was employed to decide whether to stop the path. Each ray as a final contribution to the pixel it belongs to, which is inversely proportional to the depth of the ray

\subsubsection{New Parallelization Strategy}
\label{sec:cases:ray:strat}

To use the ray tracer in a way that could favor the locality improvements shown here, a different parallelization strategy was required. The main reason for this is that, to better exploit geometrical proximity, it is better for all threads to share the processing of the same pixel, instead of processing rays from different pixels, that consequentely are more appart from each other.

Also, since at each new depth level, rays are completely unsorted due to the high divergence that is natural from Ray Tracing algorithms, it is useful to allow the rays to be sorted again and the blocks reorganized. This could also be done with the initial parallelization approach, however, it would require each ray to keep an even larger amount of auxiliary data, such as the pixel it belongs to, increasing memory footprint, and hurting locality.
This new strategy is only possible if we assume that the implementation only provides acceptable results with a very high number of samples per pixel (values lower than 10000 result in to much noise in the final result), so that they can be split accross enough blocks and threads. 



%It should be noted that there are other proven methods of optimizing a ray tracer, that provide better speed improvements and are not compatible